{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data_type', default='index', help=\"Index or Time\")\n",
    "# parser.add_argument('--data_dir', default='data/', help=\"The path of data folder\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "data_dir = '/tmp2/yhchen/Default_Prediction_Research_Project/data/8_labels_index/len_06/'\n",
    "sample_data_dir = '/tmp2/yhchen/Default_Prediction_Research_Project/data/8_labels_index_sample/len_06/'\n",
    "all_company_id_path = '/tmp2/yhchen/Default_Prediction_Research_Project/data/all_company_id.csv'\n",
    "\n",
    "\n",
    "# compression = \"gzip\" if \".gz\" in data_dir else None\n",
    "compression = \"gzip\"\n",
    "\n",
    "\n",
    "# all_company_id = pd.read_csv(all_company_id_path)\n",
    "# company_sample_id = all_company_id.sample(n=500, random_state=1)\n",
    "\n",
    "sample_train_df = pd.DataFrame()\n",
    "sample_test_df = pd.DataFrame()\n",
    "\n",
    "for i in trange(1, 13):\n",
    "    # Join folder\n",
    "    fold_dir = data_dir + \"index_fold_{:02d}\".format(i)\n",
    "    sample_fold_dir = sample_data_dir + \"index_fold_{:02d}\".format(i)\n",
    "\n",
    "    # Make folder if not exist\n",
    "    if not os.path.isdir(sample_fold_dir):\n",
    "        os.makedirs(sample_fold_dir)\n",
    "\n",
    "    # Confirm load & save path\n",
    "    test_path = os.path.join(fold_dir, 'test_cum.gz')\n",
    "    train_path = os.path.join(fold_dir, 'train_cum.gz')\n",
    "    sample_test_path = os.path.join(sample_fold_dir, 'test_cum.gz')\n",
    "    sample_train_path = os.path.join(sample_fold_dir, 'train_cum.gz')\n",
    "\n",
    "    # sklearn stratified sampling (default number or company number)\n",
    "\n",
    "    # sampling\n",
    "    train_df = pd.read_csv(train_path, compression=compression, header=0)\n",
    "    test_df = pd.read_csv(test_path, compression=compression, header=0)\n",
    "\n",
    "    sample_id = pd.DataFrame(train_df[train_df['id'].isin(test_df['id'])].id.unique(), columns=['id'])\n",
    "    sample_id = sample_id.id.sample(n=500, random_state=1, replace = False)\n",
    "\n",
    "    sample_train_df = train_df[train_df['id'].isin(sample_id)]\n",
    "    sample_test_df = test_df[test_df['id'].isin(sample_id)]\n",
    "\n",
    "    # write a pandas dataframe to gzipped CSV file\n",
    "    sample_train_df.to_csv(sample_train_path, index=False, compression=\"gzip\")\n",
    "    sample_test_df.to_csv(sample_test_path, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The path of merged.csv\n",
    "merge_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/merged.csv\"\n",
    "merge_df = pd.read_csv(merge_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Sampling\n",
    "\n",
    "# Random Sampling\n",
    "\n",
    "sample_id = pd.DataFrame(merge_df.id.unique(), columns=['id'])\n",
    "sample_id = sample_id.id.sample(n=500, random_state=1, replace = False)\n",
    "\n",
    "sample_merge_df = merge_df[merge_df['id'].isin(sample_id)]\n",
    "\n",
    "# Save file\n",
    "sample_merge_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/sample\" # save path (folder)\n",
    "# sample_merge_df.to_csv(sample_merge_path + \"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling according to distribution\n",
    "\n",
    "# Sampling by distribution\n",
    "\n",
    "b = merge_df.groupby('date')\n",
    "default_list = list(b['y_cum_01'].sum())\n",
    "time_list = list(b.size().index)\n",
    "\n",
    "time_default = {}\n",
    "for key, value in zip(time_list, default_list):\n",
    "    time_default[key] = value\n",
    "\n",
    "sample_id = pd.DataFrame(merge_df.id.unique(), columns=['id'])\n",
    "\n",
    "id_default = {}\n",
    "for id in sample_id.id:\n",
    "    id_default[id] = 0\n",
    "\n",
    "id_list = list(merge_df[merge_df['y_cum_01'] == 1]['id'])\n",
    "time_list = list(merge_df[merge_df['y_cum_01'] == 1]['date'])\n",
    "for key, time_idx in zip(id_list, time_list):\n",
    "    id_default[key] = time_default[time_idx]\n",
    "\n",
    "df_sample = pd.DataFrame(list(zip(list(id_default.keys()), list(id_default.values()))), columns =['id', 'weights'])\n",
    "\n",
    "sample_id = df_sample.sample(n=500, random_state=1, replace = False, weights='weights')\n",
    "\n",
    "sample_merge_df = merge_df[merge_df['id'].isin(sample_id.id)]\n",
    "\n",
    "# Save file\n",
    "sample_merge_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/sample/\" # save path (folder)\n",
    "# sample_merge_df.to_csv(sample_merge_path + \"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sampling according to distribution\n",
    "compression = \"gzip\"\n",
    "train_path1 = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/merged.csv\"\n",
    "\n",
    "a = pd.read_csv(train_path1, header=0)\n",
    "a['y_cum_01'] = a['y_cum_01'].replace({-1:0, 2:0})\n",
    "\n",
    "b = a.groupby('date')\n",
    "default_list = list(b['y_cum_01'].sum())\n",
    "time_list = list(b.size().index)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(zip(time_list, default_list)), columns =['date', 'default_number'])\n",
    "df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(df.date, df.default_number, color = '#00A2FF', edgecolor=\"#00A2FF\", label = \"Actual\", width=20, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Default numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_merge_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/sample/\" # save path (folder)\n",
    "a = pd.read_csv(sample_merge_path + \"merged.csv\", header=0)\n",
    "a['y_cum_01'] = a['y_cum_01'].replace({-1:0, 2:0})\n",
    "b = a.groupby('date')\n",
    "default_list_sample = list(b['y_cum_01'].sum())\n",
    "time_list_sample = list(b.size().index)\n",
    "\n",
    "df_sample = pd.DataFrame(list(zip(time_list_sample, default_list_sample)), columns =['date', 'default_number'])\n",
    "df_sample['date'] = pd.to_datetime(df_sample['date'],format='%Y-%m-%d')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(df.date, df.default_number, color = '#00A2FF', edgecolor=\"#00A2FF\", label = \"Actual\", width=20, alpha=0.7)\n",
    "plt.bar(df_sample.date, df_sample.default_number, color = 'red', edgecolor=\"red\", label = \"Sample\", width=20, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Default numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read merged.csv ...\n",
      "Read pred.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "<string>:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import relativedelta\n",
    "import numpy as np\n",
    "\n",
    "def plot_distribution(pred_path):\n",
    "    # pred_path\n",
    "    # pred_path = \"/tmp2/cwlin/explainable_credit/explainable_credit/experiments/gru01_index/\"\n",
    "    pred_file = \"pred.csv\"\n",
    "\n",
    "    print(\"Read merged.csv ...\")\n",
    "    merge_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/codes/data/interim/merged.csv\"\n",
    "    merge_df = pd.read_csv(merge_path, header=0, index_col=False)\n",
    "    print(\"Read pred.csv ...\")\n",
    "\n",
    "    pred_df = pd.DataFrame()\n",
    "\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    # Read from 13 folds\n",
    "    for i in range(1, 13):\n",
    "        if i > 9:\n",
    "            read_path = pred_path + 'index_fold_' + str(i) + '/' + pred_file\n",
    "        else:\n",
    "            read_path = pred_path + 'index_fold_0' + str(i) + '/' + pred_file\n",
    "        df = pd.read_csv(read_path, header=0, index_col=False)\n",
    "        pred_df = pd.concat([pred_df, df])\n",
    "\n",
    "    # df = merge_df.merge(df, how ='inner', on =['date', 'id'])\n",
    "\n",
    "    for i in range(1, 9):\n",
    "        label_horizon = 'y_cum_0' + str(i)\n",
    "        pred_horizon = 'p_cum_0' + str(i)\n",
    "\n",
    "        # all_df = df.drop(index=df[df[pred_horizon] == -1].index)\n",
    "        # all_df = all_df.drop(index=all_df[all_df[pred_horizon] == 2].index)\n",
    "        all_df = pred_df\n",
    "        all_df[pred_horizon] = all_df[pred_horizon].replace(-1, 0)\n",
    "        all_df[pred_horizon] = all_df[pred_horizon].replace(2, 0)\n",
    "        all_df = all_df.groupby('date')\n",
    "\n",
    "        # df_label = merge_df.drop(index=merge_df[merge_df[label_horizon] == -1].index)\n",
    "        # df_label = df_label.drop(index=df_label[df_label[label_horizon] == 2].index)\n",
    "        df_label = merge_df\n",
    "        df_label[label_horizon] = df_label[label_horizon].replace(-1, 0)\n",
    "        df_label[label_horizon] = df_label[label_horizon].replace(2, 0)\n",
    "        df_label = df_label.groupby('date')\n",
    "\n",
    "        # label_list.append(list(all_df[label_horizon].mean()))\n",
    "        # pred_list.append(list(all_df[pred_horizon].mean()))\n",
    "\n",
    "        # label_list.append(list(all_df[label_horizon].sum()))\n",
    "        # pred_list.append(list(all_df[pred_horizon].sum()))\n",
    "\n",
    "        label_list = list(df_label[label_horizon].sum())\n",
    "        pred_list = list(all_df[pred_horizon].sum())\n",
    "        # pred_list = [x/13 for x in pred_list]\n",
    "        time_list = list(all_df.size().index)\n",
    "\n",
    "        print(\"Plot distribution of prediction and actual ...\")\n",
    "        df = pd.DataFrame(list(zip(time_list, pred_list, label_list)), columns =['date', 'pred_number', 'actual'])\n",
    "        df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "        # df['date'] = df['date'] + relativedelta.relativedelta(months=predict_horizon-1)\n",
    "\n",
    "        plt.bar(df.date, df.actual, color = '#00A2FF', edgecolor=\"#00A2FF\", label = \"Actual\", width=20, alpha=0.7)\n",
    "        plt.bar(df.date, df.pred_number, color = 'red', edgecolor=\"red\", label = \"Predict\", width=20, alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.title('prediction horizon = ' + str(i))\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Default numbers')\n",
    "        plt.show()\n",
    "\n",
    "plot_distribution(pred_path = \"/tmp2/cwlin/explainable_credit/explainable_credit/experiments/gru01_index/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from model import *\n",
    "from main import *\n",
    "\n",
    "json_path = \"/tmp2/yhchen/Default_Prediction_Research_Project/explainable_credit/experiments/gru06_index/index_fold_03/params.json\"\n",
    "params = Params(json_path)\n",
    "\n",
    "params.batch_size = 1\n",
    "params.num_stock = 15786\n",
    "params.alpha = 0.2\n",
    "params.heads_att = 6\n",
    "params.hidn_att = 60\n",
    "params.relation_static = 0\n",
    "\n",
    "model = Neural_Default_Prediction_revised(params=params, adgat_relation=False)\n",
    "\n",
    "x = torch.randn(6, 15786, 14).requires_grad_(True)  # 定义一个网络的输入值\n",
    "y = model(x)    # 获取网络的预测值\n",
    "\n",
    "MyConvNetVis = make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))\n",
    "MyConvNetVis.format = \"png\"\n",
    "# 指定文件生成的文件夹\n",
    "MyConvNetVis.directory = \"data\"\n",
    "# 生成文件\n",
    "MyConvNetVis.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from model import *\n",
    "from main import *\n",
    "\n",
    "class test_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test_model, self).__init__()\n",
    "\n",
    "        self.GRUs_r = Graph_GRUModel(num_nodes=15786, input_dim=14, hidden_dim=64)\n",
    "\n",
    "        # self.gru_r = nn.GRU(input_size=14, hidden_size=64, batch_first=True)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset_parameters(self.named_parameters)\n",
    "\n",
    "    def forward(self, x_r):\n",
    "        # output, x_r = self.gru_r(input=x_r)\n",
    "        x_r = self.GRUs_r(x_r)\n",
    "        \n",
    "        return x_r\n",
    "\n",
    "model = test_model()\n",
    "\n",
    "x = torch.randn(6, 15786, 14).requires_grad_(True)  # 定义一个网络的输入值\n",
    "y = model(x)    # 获取网络的预测值\n",
    "\n",
    "MyConvNetVis = make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))\n",
    "MyConvNetVis.format = \"png\"\n",
    "# 指定文件生成的文件夹\n",
    "MyConvNetVis.directory = \"data\"\n",
    "# 生成文件\n",
    "MyConvNetVis.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as h\n",
    "from model import *\n",
    "from main import *\n",
    "\n",
    "class test_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test_model, self).__init__()\n",
    "\n",
    "        self.gru_r = nn.GRU(input_size=14, hidden_size=64, batch_first=True)\n",
    "        # self.GRUs_r = Graph_GRUModel(num_nodes=15786, input_dim=14, hidden_dim=64)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset_parameters(self.named_parameters)\n",
    "\n",
    "    def forward(self, x_r):\n",
    "        output, x_r = self.gru_r(input=x_r)\n",
    "        # x_r = self.GRUs_r(x_r)\n",
    "        \n",
    "        return x_r\n",
    "\n",
    "model = test_model()\n",
    "vis_graph = h.build_graph(model, torch.zeros([6, 15786, 14]))   # 获取绘制图像的对象\n",
    "vis_graph.theme = h.graph.THEMES[\"blue\"].copy()     # 指定主题颜色\n",
    "vis_graph.save(\"./demo1.png\")   # 保存图像的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a7a948664f7892071c84d5d9b845f7a2c0dac6097ef32eb4307994a6fc2ee7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
